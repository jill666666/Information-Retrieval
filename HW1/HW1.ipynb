{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37164bitanaconda3virtualenv9667510b2071428d91179188bf356bff",
   "display_name": "Python 3.7.1 64-bit ('anaconda3': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Stoplist and Docno Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "stoplist = open('./reference/stoplist.txt')\n",
    "\n",
    "docno_arr = []\n",
    "stop_arr = []\n",
    "for line in stoplist:\n",
    "    stop_arr.append(line.strip())\n",
    "stop_arr = stop_arr + ['document', 'discuss', 'report', 'include', 'describe', 'identify', 'cite', 'predict', 'new', 'two', 'state']"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'ap_data'}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "\n",
    "es.indices.create(index = 'ap_data', ignore=400, body= {\n",
    "    \"settings\" : {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 1,\n",
    "        \"max_result_window\" : 30000,\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"english_stop\": {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": stop_arr\n",
    "                },\n",
    "                \"my_stemmer\": {\n",
    "                    \"type\": \"stemmer\",\n",
    "                    \"name\": \"english\"\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"stopped\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"english_stop\",\n",
    "                        \"my_stemmer\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "      }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"text\",\n",
    "                \"fielddata\": True,\n",
    "                \"analyzer\": \"stopped\",\n",
    "                \"index_options\": \"positions\",\n",
    "                \"term_vector\": \"yes\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import bulk\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "docno_arr = []\n",
    "res = []\n",
    "\n",
    "def parse_docs(docs):\n",
    "    while '<DOC>' in docs:\n",
    "        text = \"\"\n",
    "        docend = docs.find('</DOC>')\n",
    "        substr = docs[:docend]\n",
    "        d_stt = substr.find('<DOCNO>') + len('<DOCNO>')\n",
    "        d_end = substr.find('</DOCNO>')\n",
    "        docno = substr[d_stt:d_end].strip()\n",
    "        while \"<TEXT>\" in substr:\n",
    "            t_stt = substr.find('<TEXT>') + len('<TEXT>')\n",
    "            t_end = substr.find('</TEXT>')\n",
    "            text = text + substr[t_stt:t_end].strip() + '\\n'\n",
    "            substr = substr[t_end + len('</TEXT>'):]\n",
    "        docs = docs[docend + len('</DOC>'):]\n",
    "        docno_arr.append(docno)\n",
    "        yield {\n",
    "            '_index': 'ap_data',\n",
    "            '_id': docno,\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "def bulk_index(filename):\n",
    "    with open(filename, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "        docs = f.read()\n",
    "    return bulk(es, parse_docs(docs))\n",
    "\n",
    "def docs_index(filepath):\n",
    "    for file in tqdm(os.listdir(filepath)):\n",
    "        res.append(bulk_index(os.path.join(filepath, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 365/365 [01:16<00:00,  5.59it/s]\n"
    }
   ],
   "source": [
    "docs_index('../AP_DATA/ap89_collection')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'59': ['weather', 'event', 'directli', 'caus', 'least', 'fatal', 'locat'], '77': ['poach', 'wildlif'], '94': ['crime', 'aid', 'comput'], '85': ['alleg', 'corrupt', 'public', 'govern', 'worldwid'], '95': ['comput', 'applic', 'crime', 'solv'], '91': ['armi', 'advanc', 'weapon', 'system'], '56': ['lend', 'prime', 'rate'], '71': ['incurs', 'border', 'area', 'militari', 'guerrilla'], '64': ['polit', 'motiv', 'hostag', 'take'], '62': ['militari', 'coup', \"d'etat\", 'attempt', 'successfulli'], '93': ['support', 'nation', 'rifl', 'associ', 'nra', 'asset'], '99': ['iran', 'contra', 'affair'], '58': ['rail', 'strike'], '54': ['contract', 'agreement', 'launch', 'commerci', 'satellit'], '87': ['current', 'crimin', 'offic', 'fail', 'financi', 'institut'], '100': ['non', 'communist', 'regul', 'transfer', 'high', 'tech', 'good', 'technolog', 'undesir', 'nation'], '89': ['invest', 'opec', 'downstream', 'oper'], '61': ['israel', 'iran', 'contra', 'affair'], '68': ['safeti', 'manufactur', 'employe', 'instal', 'worker', 'fine', 'diamet', 'fiber', 'insul', 'product'], '63': ['thesauru'], '57': ['mci', 'bell', 'system', 'breakup'], '97': ['fiber', 'optic', 'technolog'], '98': ['fiber', 'optic', 'equip'], '60': ['controversi', 'standard', 'perform', 'determin', 'salari', 'level', 'incent', 'pai', 'contrast', 'determin', 'pai', 'sole', 'basi', 'longev', 'job'], '80': ['platform', '1988', 'presidenti', 'candid']}\n"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "querylist = open('./reference/querylist.txt')\n",
    "query_dict = {}\n",
    "word_arr = []\n",
    "query_arr = []\n",
    "\n",
    "for line in querylist:\n",
    "    if line.strip() != '':\n",
    "        queryno = re.sub('[^A-Za-z0-9]+', '', line.split()[0])\n",
    "        query = line.split()[1:]\n",
    "        modified = line[line.find(\".\")+1:]\n",
    "        terms = es.indices.analyze(index='ap_data', body={'analyzer': 'stopped', 'text': modified})\n",
    "        for term in terms['tokens']:\n",
    "            query_arr.append(term['token'])\n",
    "        for word in query_arr:\n",
    "            if word not in stop_arr:\n",
    "                word_arr.append(word)\n",
    "        query_dict[queryno] = word_arr\n",
    "        word_arr = []\n",
    "        query_arr = []\n",
    "print(query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Important Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def doc_length(doc_id):\n",
    "    return len(es.get(index='ap_data', id=doc_id)['_source']['text'].split())\n",
    "\n",
    "def term_freq(term, doc_id):\n",
    "    res = es.termvectors(index='ap_data', id = doc_id, fields='text')['term_vectors']['text']['terms']\n",
    "    if res.get(term) is not None:\n",
    "        return res.get(term)['term_freq']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def field_stat():\n",
    "    return es.termvectors(index='ap_data', id='AP890101-0001', fields='text')['term_vectors']['text']['field_statistics']\n",
    "\n",
    "def corpus_length():\n",
    "    return field_stat()['sum_doc_freq']\n",
    "\n",
    "def tf_q(queryno, word):\n",
    "    count = Counter(query_dict[queryno])\n",
    "    return count[word]\n",
    "\n",
    "def doc_filter(word):\n",
    "    res = es.search(index='ap_data', body={\"query\": {\"match\": {\"text\": word}}, \"size\": 30000})\n",
    "    return [d['_id'] for d in res['hits']['hits']]\n",
    "\n",
    "def doc_freq(word):\n",
    "    return es.count(index='ap_data', body = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"text\" : word\n",
    "            }\n",
    "        }\n",
    "    })['count']\n",
    "\n",
    "def vocab_size():\n",
    "    search_result = es.search(index='ap_data', size=0, body={\n",
    "            \"aggs\" : {\n",
    "                \"unique_terms\" : {\n",
    "                    \"cardinality\" : {\"field\": \"text\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return int(search_result['aggregations']['unique_terms']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = es.count(index='ap_data')['count']\n",
    "\n",
    "avg_len = field_stat()['sum_ttf'] / total_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute Document Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 84679/84679 [04:41<00:00, 301.06it/s]\n"
    },
    {
     "data": {
      "text/plain": "1040"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_len_info = {}\n",
    "for docno in tqdm(docno_arr):\n",
    "    doc_len_info[docno] = doc_length(docno)\n",
    "doc_len_info['AP890101-0001']"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_info = []\n",
    "def precompute_tf(query, tf_info):\n",
    "    for key, words in query.items():\n",
    "        print(key, words)\n",
    "        for word in words:\n",
    "            docs = doc_filter(word)\n",
    "            for docno in docs:\n",
    "                freq = {'id': docno, 'word': word, 'tf': term_freq(word, docno)}\n",
    "                tf_info.append(freq)\n",
    "\n",
    "precompute_tf(query_dict, tf_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okapi_tf(tf, doc_len):\n",
    "    return tf / (tf + 0.5 + 1.5 * (doc_len/avg_len))\n",
    "\n",
    "def tf_idf(tf, doc_len, df, total_docs):\n",
    "    return okapi_tf(tf, doc_len) * math.log(total_docs / df)\n",
    "\n",
    "def okapi_bm25(tf, tf_q, doc_len, df, k1, k2, b, total_docs, avg_len):\n",
    "    return math.log((total_docs + 0.5) / (df + 0.5)) * \\\n",
    "           ((tf + k1 * tf) / (tf + k1* ((1-b) + b * (doc_len / avg_len)))) * \\\n",
    "           ((tf_q + k2 * tf_q) / (tf_q + k2))\n",
    "\n",
    "def unigram_lm_laplace(tf, doc_len, voc_size):\n",
    "    return math.log((tf + 1) / (doc_len + voc_size))\n",
    "\n",
    "def unigram_lm_jm(tf, doc_len, all_tf, all_len, lmbda):\n",
    "    frntgrd = float(tf) / doc_len\n",
    "    backgrd = float(all_tf - tf) / (all_len - doc_len)\n",
    "    return lmbda * frntgrd + (1 - lmbda) * backgrd"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_scores(key, scores, out):\n",
    "    if len(scores) < 1000:\n",
    "        iter = len(scores)\n",
    "    else:\n",
    "        iter = 1000\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for j in range(iter):\n",
    "        str = ('{} Q0 {} {} {} Exp'\n",
    "            .format(key, sorted_scores[j][0], j+1, sorted_scores[j][1]))\n",
    "        out.write(str+\"\\n\")\n",
    "    scores.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_score(docno, model_scores, score):\n",
    "    if docno in model_scores:\n",
    "        model_scores[docno] += score\n",
    "    else:\n",
    "        model_scores[docno] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ES Built-In Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_es_built_in(query):\n",
    "    out = open('./es-built-in.txt', \"a\")\n",
    "    es_built_in_scores = defaultdict(lambda: 0.0)\n",
    "    for key, words in tqdm(query.items(), position=0, leave=True, desc='Computing ES Built-In'):\n",
    "        for word in words:\n",
    "            res=es.search(index='ap_data',body={\"query\":{\"match\":{\"text\":word}},\"size\":30000})\n",
    "            for docno in res['hits']['hits']:\n",
    "                add_score(docno['_id'], es_built_in_scores, docno['_score'])\n",
    "        rank_scores(key, es_built_in_scores, out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Vector Space Models Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vs_models(query):\n",
    "    okapi_tf_out = open('./okapi-tf.txt', \"a\")\n",
    "    tf_idf_out = open('./tf-idf.txt', \"a\")\n",
    "    okapi_bm25_out = open('./okapi-bm25.txt', \"a\")\n",
    "\n",
    "    okapi_tf_scores = defaultdict(lambda: 0.0)\n",
    "    tf_idf_scores = defaultdict(lambda: 0.0)\n",
    "    okapi_bm25_scores = defaultdict(lambda: 0.0)\n",
    "\n",
    "    for key, words in tqdm(query.items(), position=0, leave=True, desc='Computing Vector Space models'):\n",
    "        for word in words:\n",
    "            new_tf_info = [element for element in tf_info if element['word'] == word]\n",
    "            docs = doc_filter(word)\n",
    "            for docno in docs:\n",
    "                tf = next(item for item in new_tf_info if item['id'] == docno)['tf']\n",
    "                df = len(docs)\n",
    "                qf = tf_q(key, word)\n",
    "                doc_len = doc_len_info[docno]\n",
    "                add_score(docno, okapi_tf_scores, okapi_tf(tf, doc_len))\n",
    "                add_score(docno, tf_idf_scores, tf_idf(tf, doc_len, df, total_docs))\n",
    "                add_score(docno, okapi_bm25_scores, okapi_bm25(tf, qf, doc_len, df, 1.2, 100, 0.75, total_docs, avg_len))\n",
    "        rank_scores(key, okapi_tf_scores, okapi_tf_out)\n",
    "        rank_scores(key, tf_idf_scores, tf_idf_out)\n",
    "        rank_scores(key, okapi_bm25_scores, okapi_bm25_out)\n",
    "    okapi_tf_out.close()\n",
    "    tf_idf_out.close()\n",
    "    okapi_bm25_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Language Models Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unigram_lm_laplace(query):\n",
    "    laplace_scores = defaultdict(lambda: 0.0)\n",
    "    out = open('./unigram-lm-laplace.txt', \"a\")\n",
    "    voc_size = vocab_size()\n",
    "    for key,words in tqdm(query.items(), position=0, leave=True, desc='Computing Language Models(Unigram-LM-Laplace)'):\n",
    "        for word in words:\n",
    "            new_tf_info = [element for element in tf_info if element['word'] == word]\n",
    "            docs=doc_filter(word)\n",
    "            for docno in docno_arr:\n",
    "                if docno in docs:\n",
    "                    tf = next(item for item in new_tf_info if item['id'] == docno)['tf']\n",
    "                    doc_len = doc_len_info[docno]\n",
    "                else:\n",
    "                    tf = 0\n",
    "                    doc_len = 0\n",
    "                score = unigram_lm_laplace(tf, doc_len, voc_size)\n",
    "                add_score(docno, laplace_scores, score)\n",
    "        rank_scores(key, laplace_scores, out)\n",
    "    out.close()\n",
    "\n",
    "def compute_unigram_lm_jm(query):\n",
    "    jelinek_scores = defaultdict(lambda: 0.0)\n",
    "    out = open('./unigram-lm-jm.txt', \"a\")\n",
    "    lmbda = .7\n",
    "    for key,words in tqdm(query.items(), position=0, leave=True, desc='Computing Language Models(Unigram-LM-JM)'):\n",
    "        for word in words:\n",
    "            new_tf_info = [element for element in tf_info if element['word'] == word]\n",
    "            docs = doc_filter(word)\n",
    "            all_tf = 0\n",
    "            all_len = 0\n",
    "            backgrd = 0\n",
    "            frntgrd = 0\n",
    "            for docno in docs:\n",
    "                tf = next(item for item in new_tf_info if item['id'] == docno)['tf']\n",
    "                all_tf = all_tf + tf\n",
    "                all_len = all_len + len(docs)\n",
    "            for docno in docs:\n",
    "                tf = next(item for item in new_tf_info if item['id'] == docno)['tf']\n",
    "                doc_len = doc_len_info[docno]\n",
    "                lmbda = .7\n",
    "                score = unigram_lm_jm(tf, doc_len, all_tf, all_len, lmbda)\n",
    "                add_score(docno, jelinek_scores, score)\n",
    "        rank_scores(key, jelinek_scores, out)\n",
    "    out.close()\n",
    "\n",
    "def compute_lang_models(query):\n",
    "    compute_unigram_lm_laplace(query)\n",
    "    compute_unigram_lm_jm(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-relevance Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_k_docs(key, scores, k, term_dict):\n",
    "    arr = []\n",
    "    temp_dict = defaultdict(lambda: 0.0)\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    if len(sorted_scores) < 1000:\n",
    "        iter = len(sorted_scores)\n",
    "    else:\n",
    "        iter = k\n",
    "    for j in range(iter):\n",
    "        arr.append(sorted_scores[j][0])\n",
    "    for docno in arr:\n",
    "        res = es.termvectors(index='ap_data', id = docno, fields='text')['term_vectors']['text']['terms']\n",
    "        for id in res:\n",
    "            if id not in temp_dict:\n",
    "                temp_dict[id] = 1\n",
    "        # print(temp_dict)\n",
    "        for word in temp_dict:\n",
    "            if word not in term_dict:\n",
    "                term_dict[word] = 1\n",
    "            else:\n",
    "                term_dict[word] += 1\n",
    "        temp_dict.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pseudo_feedback(query):\n",
    "    new_query_dict = copy.deepcopy(query)\n",
    "    count = 0\n",
    "    efficiency = []\n",
    "    term_dict = defaultdict(lambda: 0.0)\n",
    "    psdo_fdbck_scores = defaultdict(lambda: 0.0)\n",
    "    for key, words in tqdm(new_query_dict.items(), position=0, leave=True, desc='Proceeding Pseudo-relevance Feedback...'):\n",
    "        for word in words:\n",
    "            res=es.search(index='ap_data', body={\"query\":{\"match\":{\"text\":word}}, \"size\":30000})\n",
    "            for docno in res['hits']['hits']:\n",
    "                add_score(docno['_id'], psdo_fdbck_scores, docno['_score'])\n",
    "        retrieve_k_docs(key, psdo_fdbck_scores, 1000, term_dict)\n",
    "        ranks = sorted(term_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        efficiency = []\n",
    "        for i in range(20):\n",
    "            efficiency.append(ranks[i][0])\n",
    "        for j in range(len(efficiency) - 1):\n",
    "            if efficiency[j] not in new_query_dict[key]:\n",
    "                new_query_dict[key].append(efficiency[j])\n",
    "                count += 1\n",
    "            if count == 2:\n",
    "                efficiency.clear()\n",
    "                term_dict.clear()\n",
    "                ranks.clear()\n",
    "                psdo_fdbck_scores.clear()\n",
    "                count = 0\n",
    "                break\n",
    "    compute_es_built_in(new_query_dict, './feedback1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-relevance Feedback using significant terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgni_term(word):  \n",
    "    res = es.search(index='ap_data', body={\n",
    "        \"query\" : {\n",
    "            \"terms\" : {\"text\" : [ word ]}\n",
    "        },\n",
    "        \"aggregations\" : {\n",
    "            \"significantCrimeTypes\" : {\n",
    "                \"significant_terms\" : {\n",
    "                \"field\" : \"text\"             \n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"size\": 0\n",
    "    })\n",
    "    temp = [d for d in res['aggregations']['significantCrimeTypes']['buckets']][1]\n",
    "    return temp['key'], temp['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significant_terms(query):\n",
    "    sgni_dict = defaultdict(lambda: 0.0)\n",
    "    for key, words in query.items():\n",
    "        for word in words:\n",
    "            temp_key, temp_score = sgni_term(word)\n",
    "            sgni_dict[temp_key] = temp_score\n",
    "        ranks = sorted(sgni_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        if ranks[0][0] not in query[key]:\n",
    "            query[key].append(ranks[0][0])\n",
    "            # new_tf_info.append(ranks[0][0])\n",
    "        sgni_dict.clear()\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sgni_pseudo_feedback(query):\n",
    "    tf_info = []\n",
    "    new_query_dict = copy.deepcopy(query)\n",
    "    precompute_tf(significant_terms(new_query_dict), tf_info)\n",
    "    compute_es_built_in(new_query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Proceeding Pseudo-relevance Feedback...: 100%|██████████| 25/25 [03:34<00:00,  9.08s/it]\nComputing ES Built-In: 100%|██████████| 25/25 [05:34<00:00, 12.11s/it]\nPre-computing newly appended term frequencies: 100%|██████████| 23/23 [1:13:58<00:00, 295.78s/it]\nComputing ES Built-In: 100%|██████████| 25/25 [02:13<00:00,  5.58s/it]\nComputing ES Built-In: 100%|██████████| 25/25 [02:14<00:00,  5.71s/it]\nComputing Vector Space models: 100%|██████████| 25/25 [07:48<00:00, 13.59s/it]\nComputing Language Models(Unigram-LM-Laplace): 100%|██████████| 25/25 [24:31<00:00, 54.48s/it]\nComputing Language Models(Unigram-LM-JM): 100%|██████████| 25/25 [12:23<00:00, 18.72s/it]\n"
    }
   ],
   "source": [
    "compute_es_built_in(query_dict)\n",
    "compute_vs_models(query_dict)\n",
    "compute_lang_models(query_dict)\n",
    "compute_pseudo_feedback(query_dict)\n",
    "compute_sgni_pseudo_feedback(query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}